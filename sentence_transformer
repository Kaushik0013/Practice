from pypdf import PdfReader
from sentence_transformers import SentenceTransformer
import chromadb
import re
import numpy as np

# ----- LOAD LOCAL MODEL -----
model = SentenceTransformer('path/to/your/local/miniLM-model')

# ----- READ PDF -----
pdf = PdfReader("animal.pdf")
text = " ".join([p.extract_text() or "" for p in pdf.pages]).lower()

# ----- EXTRACT NOUNS (4-12 letters) -----
chunks = re.findall(r'\b[a-z]{4,12}\b', text)

# ----- CHROMA DB -----
client = chromadb.Client()
col = client.get_or_create_collection("data")
embs = model.encode(chunks).tolist()
col.add(ids=[str(i) for i in range(len(chunks))], documents=chunks, embeddings=embs)

# ----- DISCOVER FROM PDF ITSELF -----
doc_emb = model.encode([text[:300]])  # Use PDF content as query
results = col.query(query_embeddings=doc_emb, n_results=100)
top_words = results["documents"][0]

# ----- SELF-LEARN ANIMAL FILTER -----
word_embs = model.encode(top_words)
doc_context = model.encode([f"{text[:200]} {' '.join(top_words[:10])}"])
sims = np.dot(word_embs, doc_context[0]) / (np.linalg.norm(word_embs, axis=1) * np.linalg.norm(doc_context[0]))

# ----- TOP BIOLOGICALLY RELEVANT -----
animals = [w for w, s in zip(top_words, sims) if s > 0.45]
animals = list(set(animals))[:10]  # Unique, top 10

print("Animals:", sorted(animals))
